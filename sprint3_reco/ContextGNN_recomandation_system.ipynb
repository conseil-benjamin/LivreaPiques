{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([292, 246,  29, 205, 185, 183, 374, 348, 309, 473, 124, 365, 399, 235,\n",
      "        131, 428, 221, 361,  65, 410, 477, 300,  28, 303, 465,  25, 387, 265,\n",
      "        407, 238,   4, 199, 449, 467,  27, 486, 422,  13, 443, 136, 277, 413,\n",
      "        214,   8,  27, 326, 281, 429,  71, 219])\n",
      "--------------------------------------------------\n",
      "tensor([711,  78, 416, 243, 368, 487, 900, 875, 879, 881, 205, 339, 180, 520,\n",
      "        136, 873, 216, 930, 506,  72,  19, 161, 697, 140, 107, 465, 835, 855,\n",
      "        764, 113, 458,  12, 401,  30,  45, 444, 242,  94, 398, 974, 540, 693,\n",
      "         58, 251, 876, 312, 615, 310, 406, 608])\n",
      "--------------------------------------------------\n",
      "tensor([[-0.3345],\n",
      "        [-0.0546],\n",
      "        [ 0.0628],\n",
      "        [-0.0540],\n",
      "        [-0.2733],\n",
      "        [ 0.0954],\n",
      "        [ 0.1112],\n",
      "        [-0.0277],\n",
      "        [ 0.0926],\n",
      "        [-0.0582],\n",
      "        [ 0.0962],\n",
      "        [-0.2725],\n",
      "        [ 0.0816],\n",
      "        [-0.0040],\n",
      "        [ 0.0120],\n",
      "        [-0.0255],\n",
      "        [-0.0984],\n",
      "        [ 0.0976],\n",
      "        [ 0.1532],\n",
      "        [-0.1446],\n",
      "        [ 0.2556],\n",
      "        [ 0.1074],\n",
      "        [ 0.2779],\n",
      "        [-0.0295],\n",
      "        [-0.0256],\n",
      "        [-0.1165],\n",
      "        [ 0.0647],\n",
      "        [-0.1980],\n",
      "        [-0.5864],\n",
      "        [-0.0953],\n",
      "        [ 0.3276],\n",
      "        [ 0.2126],\n",
      "        [ 0.4385],\n",
      "        [ 0.1927],\n",
      "        [-0.0800],\n",
      "        [-0.1622],\n",
      "        [-0.3232],\n",
      "        [-0.1534],\n",
      "        [-0.6064],\n",
      "        [-0.3308],\n",
      "        [-0.0930],\n",
      "        [ 0.0242],\n",
      "        [-0.1451],\n",
      "        [ 0.4290],\n",
      "        [-0.0525],\n",
      "        [-0.1882],\n",
      "        [-0.2027],\n",
      "        [ 0.0633],\n",
      "        [-0.1066],\n",
      "        [ 0.1678]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class ContextGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(ContextGNN, self).__init__()\n",
    "        \n",
    "        # Backbone GNN\n",
    "        self.gnn = Sequential('x, edge_index', [\n",
    "            (SAGEConv(in_channels, hidden_channels), 'x, edge_index -> x'),\n",
    "            torch.nn.ReLU(),\n",
    "            (SAGEConv(hidden_channels, hidden_channels), 'x, edge_index -> x'),  # Sortie = hidden_channels\n",
    "        ])\n",
    "        \n",
    "        # Pair-wise scorer\n",
    "        self.pairwise_mlp = torch.nn.Linear(hidden_channels, 1)\n",
    "        \n",
    "        # Two-tower scorer\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=1000, embedding_dim=hidden_channels)\n",
    "        self.user_tower = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.item_tower = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        \n",
    "        # Fusion scorer\n",
    "        self.fusion_mlp = torch.nn.Linear(hidden_channels, 1)\n",
    "    \n",
    "    def forward(self, x, edge_index, user_ids, item_ids):\n",
    "        # Local subgraph (pair-wise) GNN representation\n",
    "        user_item_features = self.gnn(x, edge_index)  # Sortie : (500, hidden_channels)\n",
    "        \n",
    "        # Filtrer les pairwise_scores pour les user_ids\n",
    "        pairwise_scores = self.pairwise_mlp(user_item_features)  # (500, 1)\n",
    "        pairwise_scores = pairwise_scores[user_ids]  # (50, 1)\n",
    "        \n",
    "        # Two-tower representation\n",
    "        user_emb = self.user_tower(user_item_features[user_ids])  # (50, out_channels)\n",
    "        item_emb = self.item_tower(self.item_embedding(item_ids))  # (50, out_channels)\n",
    "        twotower_scores = torch.sum(user_emb * item_emb, dim=1, keepdim=True)  # (50, 1)\n",
    "        \n",
    "        # Fusion of pair-wise and two-tower scores\n",
    "        fusion_score = self.fusion_mlp(user_item_features[user_ids])  # (50, 1)\n",
    "        final_scores = pairwise_scores + fusion_score * twotower_scores  # (50, 1)\n",
    "        return final_scores\n",
    "\n",
    "\n",
    "\n",
    "# Dummy data for testing\n",
    "node_features = torch.randn((500, 64))  # 500 nodes with 64 features each\n",
    "edges = torch.randint(0, 500, (2, 2000))  # 2000 edges\n",
    "user_ids = torch.randint(0, 500, (50,))  # 50 users\n",
    "print(user_ids)\n",
    "print('-'*50)\n",
    "item_ids = torch.randint(0, 1000, (50,))  # 50 items (predefined embedding size)\n",
    "print(item_ids)\n",
    "print('-'*50)\n",
    "\n",
    "# Model setup\n",
    "model = ContextGNN(in_channels=64, hidden_channels=128, out_channels=64)\n",
    "scores = model(node_features, edges, user_ids, item_ids)\n",
    "print(scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
